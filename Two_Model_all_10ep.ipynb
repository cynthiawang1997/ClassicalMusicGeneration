{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.random import choice, shuffle\n",
    "import tqdm.notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LeakyReLU\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, GRU\n",
    "from keras.models import Model, Sequential\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/all_song.pickle','rb') as read_file:\n",
    "    all_song= pickle.load(read_file)\n",
    "with open('pickle/notes_index_dict.pickle','rb') as read_file:\n",
    "    notes_index_dict= pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "  inputs = Input(shape=(seq_len,))\n",
    "  embedding = Embedding(input_dim=unique_notes+1, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "  forward_pass = Bidirectional(GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "  forward_pass , att_vector = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = Dropout(dropout)(forward_pass)\n",
    "  forward_pass = Bidirectional(GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "  forward_pass , att_vector2 = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = Dropout(dropout)(forward_pass)\n",
    "  forward_pass = Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "  forward_pass = Dropout(dropout)(forward_pass)\n",
    "  forward_pass = Dense(dense_unit)(forward_pass)\n",
    "  forward_pass = LeakyReLU()(forward_pass)\n",
    "  outputs = Dense(unique_notes+1, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = len(notes_index_dict)\n",
    "seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(seq_len, unique_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generate_scores_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           11601800  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 256)           176640    \n",
      "_________________________________________________________________\n",
      "seq_self_attention (SeqSelfA [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 256)           296448    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_1 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 116018)            7541170   \n",
      "=================================================================\n",
      "Total params: 20,060,028\n",
      "Trainable params: 20,060,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "  \n",
    "    def __init__(self, epochs, train, target, batch_nnet_size, batch_song, optimizer, loss_fn,\n",
    "                total_songs, model):\n",
    "        self.epochs = epochs\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "        self.batch_nnet_size = batch_nnet_size\n",
    "        self.batch_song = batch_song\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.total_songs = total_songs\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self):\n",
    "        for epoch in tqdm.notebook.tqdm(range(self.epochs),desc='epochs'):\n",
    "            \n",
    "            # for each epochs, we shuffle the list of all the datasets\n",
    "            train_target = list(zip(self.train, self.target))\n",
    "            shuffle(train_target)\n",
    "            self.train, self.target = zip(*train_target)\n",
    "            loss_total = 0\n",
    "            steps = 0\n",
    "            steps_nnet = 0\n",
    "\n",
    "            # In each epoch, iterate all songs by the size of batch_song\n",
    "            for i in tqdm.notebook.tqdm(range(0,self.total_songs, self.batch_song), desc='MUSIC'):\n",
    "\n",
    "                steps += 1\n",
    "                \n",
    "                input_batch = [y for x in self.train[i:i+self.batch_song] for y in x]\n",
    "                output_batch = [y for x in self.target[i:i+self.batch_song] for y in x]\n",
    "                inputs_nnet_large = np.array(input_batch)\n",
    "                outputs_nnet_large = np.array(output_batch)\n",
    "\n",
    "                index_shuffled = np.arange(start=0, stop=len(inputs_nnet_large))\n",
    "                np.random.shuffle(index_shuffled)\n",
    "                \n",
    "                # process the windows/target in batches\n",
    "                for nnet_steps in tqdm.notebook.tqdm(range(0,len(index_shuffled),self.batch_nnet_size)):\n",
    "                    steps_nnet += 1\n",
    "                    current_index = index_shuffled[nnet_steps:nnet_steps+self.batch_nnet_size]\n",
    "\n",
    "                    inputs_nnet, outputs_nnet = inputs_nnet_large[current_index], outputs_nnet_large[current_index]\n",
    "\n",
    "                    # To make sure no exception thrown by tensorflow on autograph\n",
    "                    if len(inputs_nnet) // self.batch_nnet_size != 1:\n",
    "                        break\n",
    "                    loss = self.train_step(inputs_nnet, outputs_nnet)\n",
    "                    loss_total += tf.math.reduce_sum(loss)\n",
    "                    if steps_nnet % 20 == 0:\n",
    "                        print(\"epochs {} | Steps {} | total loss : {}\".format(epoch + 1, steps_nnet,loss_total))\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self.model(inputs)\n",
    "            loss = self.loss_fn(targets, prediction)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "target = []\n",
    "\n",
    "for song in all_song:\n",
    "    train.append(song['train'])\n",
    "    target.append(song['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam()\n",
    "loss_fn = sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "EPOCHS = 10\n",
    "BATCH_SONG = 100\n",
    "BATCH_NNET_SIZE = 600\n",
    "TOTAL_SONGS = len(all_song)\n",
    "\n",
    "train_class = TrainModel(EPOCHS, train, target,\n",
    "                  BATCH_NNET_SIZE, BATCH_SONG, optimizer, loss_fn, TOTAL_SONGS, model)\n",
    "\n",
    "train_class.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('all_100sb_10ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
